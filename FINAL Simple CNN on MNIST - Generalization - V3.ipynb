{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN on MNIST - Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Chris/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.attacks import (BasicIterativeMethod, CarliniWagnerL2, DeepFool, ElasticNetMethod, \n",
    "                                FastFeatureAdversaries, FastGradientMethod, LBFGS, MadryEtAl, \n",
    "                                MomentumIterativeMethod, SPSA, SaliencyMapMethod, VirtualAdversarialMethod)\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_saved_model = False\n",
    "run_attack = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in Getting the Data\n",
    "train_start=0\n",
    "train_end=60000\n",
    "test_start=0\n",
    "test_end=10000\n",
    "\n",
    "attack_start=0\n",
    "attack_end=100\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 500\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "gen_steps = 11\n",
    "\n",
    "num_points = 10\n",
    "attack_names = ['basic_iterative', 'fast_gradient', 'madry', 'momentum_iterative']\n",
    "\n",
    "run_ident = '18'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Tensorflow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.core.K.set_learning_phase(0)\n",
    "\n",
    "# Set TF random seed to improve reproducibility\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "# Create TF session and set as Keras backend session\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "X_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_mnist(train_start=train_start,\n",
    "                                              train_end=train_end,\n",
    "                                              test_start=test_start,\n",
    "                                              test_end=test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input TF placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "# Define TF model graph\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "preds = model(x)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Adversarial Generation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenAdv(object):\n",
    "    def __init__(self, session):\n",
    "        self.session = session\n",
    "        self.model = None\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "    \n",
    "    def evaluate_model(self, model, data, labels, attack_names, num_points=10):\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "        attack_strengths = np.linspace(0, 0.5, num_points)\n",
    "        \n",
    "        losses = np.zeros((len(attack_names), num_points))\n",
    "        accuracies = np.zeros((len(attack_names), num_points))\n",
    "        \n",
    "        for index_name, attack_name in enumerate(attack_names):\n",
    "            print('Running attack: {}'.format(attack_name))\n",
    "            for index_strength, attack_strength in enumerate(attack_strengths):\n",
    "                print('Using attack strength: {}'.format(attack_strength))\n",
    "                loss, accuracy = self.run_attack(attack_name, attack_strength)\n",
    "                losses[index_name, index_strength] = loss\n",
    "                accuracies[index_name, index_strength] = accuracy\n",
    "            \n",
    "        return losses, accuracies\n",
    "    \n",
    "    def run_attack(self, attack_name, attack_strength):\n",
    "        wrap = KerasModelWrapper(self.model)\n",
    "        \n",
    "        if attack_name is 'basic_iterative':\n",
    "            attack = BasicIterativeMethod(wrap, sess=self.session)\n",
    "            attack_params = {'eps': attack_strength, # Default O.3\n",
    "                             'eps_iter': 0.05,\n",
    "                             'nb_iter': 10,\n",
    "                             'y': self.labels,\n",
    "                             'ord': np.inf,\n",
    "                             'clip_min': None,\n",
    "                             'clip_max': None}\n",
    "        elif attack_name is 'carlini_wagner':\n",
    "            attack = CarliniWagnerL2(wrap, sess=self.session)\n",
    "            attack_params = {'y': self.labels,\n",
    "                             'nb_classes': None,\n",
    "                             'batch_size': 1,\n",
    "                             'confidence': attack_strength, # Default 0\n",
    "                             'learning_rate': 0.005,\n",
    "                             'binary_search_steps': 5,\n",
    "                             'max_iterations': 1000,\n",
    "                             'abort_early': True,\n",
    "                             'initial_const': 0.01,\n",
    "                             'clip_min': 0,\n",
    "                             'clip_max': 1}\n",
    "        elif attack_name is 'deep_fool':\n",
    "            attack = DeepFool(wrap, sess=self.session)\n",
    "            attack_params = {'nb_candidate': attack_strength, # Default 10, INT\n",
    "                             'overshoot': 0.02,\n",
    "                             'max_iter': 50,\n",
    "                             'nb_classes': None,\n",
    "                             'clip_min': 0.0,\n",
    "                             'clip_max': 1.0}\n",
    "        elif attack_name is 'elastic_net':\n",
    "            attack = ElasticNetMethod(wrap, sess=self.session)\n",
    "            attack_params = {'y': self.labels,\n",
    "                             'nb_classes': None,\n",
    "                             'fista': True,\n",
    "                             'beta': 0.001,\n",
    "                             'decision_rule': 'EN',\n",
    "                             'batch_size': 1,\n",
    "                             'confidence': attack_strength, # Default 0\n",
    "                             'learning_rate': 0.01,\n",
    "                             'binary_search_steps': 9,\n",
    "                             'max_iterations': 1000,\n",
    "                             'abort_early': False,\n",
    "                             'initial_const': 0.001,\n",
    "                             'clip_min': 0,\n",
    "                             'clip_max': 1}\n",
    "        elif attack_name is 'fast_feature':\n",
    "            attack = FastFeatureAdversaries(wrap, sess=self.session)\n",
    "            attack_params = {'eps': attack_strength, # Default 0.3\n",
    "                             'eps_iter': 0.05,\n",
    "                             'nb_iter': 10,\n",
    "                             'ord': np.inf,\n",
    "                             'clip_min': None,\n",
    "                             'clip_max': None}\n",
    "        elif attack_name is 'fast_gradient':\n",
    "            attack = FastGradientMethod(wrap, sess=self.session)\n",
    "            attack_params = {'eps': attack_strength, # Default 0.3\n",
    "                             'ord': np.inf,\n",
    "                             'y': self.labels,\n",
    "                             'clip_min': None,\n",
    "                             'clip_max': None}\n",
    "        elif attack_name is 'lbfgs':\n",
    "            attack = LBFGS(wrap, sess=self.session)\n",
    "            attack_params = {'batch_size': 1,\n",
    "                             'binary_search_steps': 5,\n",
    "                             'max_iterations': 1000,\n",
    "                             'initial_const': attack_strength, # Default 0.01\n",
    "                             'clip_min': 0,\n",
    "                             'clip_max': 1}\n",
    "        elif attack_name is 'madry':\n",
    "            attack = MadryEtAl(wrap, sess=self.session)\n",
    "            attack_params = {'eps': attack_strength, # Default 0.3\n",
    "                             'eps_iter': 0.01,\n",
    "                             'nb_iter': 40,\n",
    "                             'y': self.labels,\n",
    "                             'ord': np.inf,\n",
    "                             'clip_min': None,\n",
    "                             'clip_max': None,\n",
    "                             'rand_init': True}\n",
    "        elif attack_name is 'momentum_iterative':\n",
    "            attack = MomentumIterativeMethod(wrap, sess=self.session)\n",
    "            attack_params = {'eps': attack_strength, # Default 0.3\n",
    "                             'eps_iter': 0.06,\n",
    "                             'nb_iter': 10,\n",
    "                             'y': self.labels,\n",
    "                             'ord': np.inf,\n",
    "                             'decay_factor': 1.0,\n",
    "                             'clip_min': None,\n",
    "                             'clip_max': None}\n",
    "        elif attack_name is 'spsa':\n",
    "            attack = SPSA(wrap, sess=self.session)\n",
    "            attack_params = {'y': self.labels,\n",
    "                             'epsilon': attack_strength, # Default None\n",
    "                             'num_steps': None,\n",
    "                             'is_targeted': False,\n",
    "                             'early_stop_loss_threshold': None,\n",
    "                             'learning_rate': 0.01,\n",
    "                             'delta': 0.01,\n",
    "                             'batch_size': 128,\n",
    "                             'spsa_iters': 1,\n",
    "                             'is_debug': False}\n",
    "        elif attack_name is 'saliency_map':\n",
    "            attack = SaliencyMapMethod(wrap, sess=self.session)\n",
    "            attack_params = {'theta': attack_strength, # Default 1.0\n",
    "                             'gamma': 1.0,\n",
    "                             'nb_classes': None,\n",
    "                             'clip_min': 0.0,\n",
    "                             'clip_max': 1.0,\n",
    "                             'symbolic_impl': True}\n",
    "        elif attack_name is 'virtual_adversarial':\n",
    "            attack = VirtualAdversarialMethod(wrap, sess=self.session)\n",
    "            attack_params = {'eps': attack_strength, # Default 2.0\n",
    "                             'num_iterations': 1,\n",
    "                             'xi': 1e-06,\n",
    "                             'clip_min': None,\n",
    "                             'clip_max': None}\n",
    "        else:\n",
    "            raise ValueError('Invalid Attack Name!')\n",
    "        \n",
    "        adv_x = attack.generate(x, **attack_params)\n",
    "        data_adv = adv_x.eval(feed_dict={x:self.data}, session=self.session)\n",
    "        \n",
    "        score = model.evaluate(data_adv, self.labels, verbose=0)\n",
    "        loss = score[0]\n",
    "        accuracy = score[1]\n",
    "        \n",
    "        return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Epoch on Security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen: 10\n",
      "Proability of Randomization: 1.0\n",
      "Rand mean (only shuffled): 0.10108333333333333\n",
      "Rand mean (Should be 1): 1.0\n",
      "Rand mean (all): 0.10108333333333333\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 2.3020 - acc: 0.1116 - val_loss: 2.3003 - val_acc: 0.1135\n",
      "Epoch 2/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.3012 - acc: 0.1123 - val_loss: 2.2942 - val_acc: 0.1135\n",
      "Epoch 3/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.3004 - acc: 0.1128 - val_loss: 2.2948 - val_acc: 0.1148\n",
      "Epoch 4/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2993 - acc: 0.1154 - val_loss: 2.2841 - val_acc: 0.1428\n",
      "Epoch 5/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2962 - acc: 0.1190 - val_loss: 2.2862 - val_acc: 0.1409\n",
      "Epoch 6/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2911 - acc: 0.1261 - val_loss: 2.3200 - val_acc: 0.1060\n",
      "Epoch 7/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2811 - acc: 0.1385 - val_loss: 2.3147 - val_acc: 0.1275\n",
      "Epoch 8/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2631 - acc: 0.1522 - val_loss: 2.2919 - val_acc: 0.1451\n",
      "Epoch 9/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2296 - acc: 0.1755 - val_loss: 2.3523 - val_acc: 0.1110\n",
      "Epoch 10/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.1753 - acc: 0.2071 - val_loss: 2.3943 - val_acc: 0.1058\n",
      "Epoch 11/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.0896 - acc: 0.2472 - val_loss: 2.4515 - val_acc: 0.0987\n",
      "Epoch 12/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.9669 - acc: 0.3022 - val_loss: 2.6879 - val_acc: 0.0820\n",
      "Epoch 13/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.8062 - acc: 0.3660 - val_loss: 2.6973 - val_acc: 0.1132\n",
      "Epoch 14/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.6137 - acc: 0.4403 - val_loss: 2.9767 - val_acc: 0.1040\n",
      "Epoch 15/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.4036 - acc: 0.5204 - val_loss: 3.2305 - val_acc: 0.0971\n",
      "Epoch 16/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.1850 - acc: 0.6004 - val_loss: 3.7342 - val_acc: 0.0943\n",
      "Epoch 17/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.9777 - acc: 0.6729 - val_loss: 4.0404 - val_acc: 0.1045\n",
      "Epoch 18/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.7859 - acc: 0.7400 - val_loss: 4.7106 - val_acc: 0.0948\n",
      "Epoch 19/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.6224 - acc: 0.7968 - val_loss: 5.0153 - val_acc: 0.1085\n",
      "Epoch 20/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4821 - acc: 0.8440 - val_loss: 5.7581 - val_acc: 0.1027\n",
      "Epoch 21/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3766 - acc: 0.8802 - val_loss: 6.3983 - val_acc: 0.1060\n",
      "Epoch 22/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2916 - acc: 0.9095 - val_loss: 6.7833 - val_acc: 0.1099\n",
      "Epoch 23/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2276 - acc: 0.9300 - val_loss: 7.3581 - val_acc: 0.1032\n",
      "Epoch 24/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1775 - acc: 0.9463 - val_loss: 8.0414 - val_acc: 0.0966\n",
      "Epoch 25/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1440 - acc: 0.9577 - val_loss: 8.4652 - val_acc: 0.0939\n",
      "Epoch 26/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1165 - acc: 0.9661 - val_loss: 8.7435 - val_acc: 0.0997\n",
      "Epoch 27/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0941 - acc: 0.9725 - val_loss: 8.9194 - val_acc: 0.1014\n",
      "Epoch 28/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0794 - acc: 0.9767 - val_loss: 9.0618 - val_acc: 0.1041\n",
      "Epoch 29/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0641 - acc: 0.9821 - val_loss: 9.5502 - val_acc: 0.1032\n",
      "Epoch 30/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0528 - acc: 0.9848 - val_loss: 9.8584 - val_acc: 0.0983\n",
      "Epoch 31/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0433 - acc: 0.9884 - val_loss: 9.9824 - val_acc: 0.1002\n",
      "Epoch 32/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0392 - acc: 0.9892 - val_loss: 9.9781 - val_acc: 0.1096\n",
      "Epoch 33/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0325 - acc: 0.9914 - val_loss: 10.3227 - val_acc: 0.0990\n",
      "Epoch 34/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0307 - acc: 0.9917 - val_loss: 10.4064 - val_acc: 0.0998\n",
      "Epoch 35/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0255 - acc: 0.9934 - val_loss: 10.6488 - val_acc: 0.0993\n",
      "Epoch 36/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0223 - acc: 0.9941 - val_loss: 10.5360 - val_acc: 0.1074\n",
      "Epoch 37/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0217 - acc: 0.9942 - val_loss: 10.5611 - val_acc: 0.1023\n",
      "Epoch 38/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0175 - acc: 0.9955 - val_loss: 10.8713 - val_acc: 0.1036\n",
      "Epoch 39/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0150 - acc: 0.9965 - val_loss: 10.6929 - val_acc: 0.1044\n",
      "Epoch 40/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0114 - acc: 0.9974 - val_loss: 10.9297 - val_acc: 0.1051\n",
      "Epoch 41/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0090 - acc: 0.9980 - val_loss: 11.0234 - val_acc: 0.1028\n",
      "Epoch 42/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0075 - acc: 0.9984 - val_loss: 11.0996 - val_acc: 0.1016\n",
      "Epoch 43/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0069 - acc: 0.9987 - val_loss: 11.2995 - val_acc: 0.0989\n",
      "Epoch 44/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0045 - acc: 0.9993 - val_loss: 11.2988 - val_acc: 0.1025\n",
      "Epoch 45/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0028 - acc: 0.9995 - val_loss: 11.3793 - val_acc: 0.1004\n",
      "Epoch 46/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 11.4172 - val_acc: 0.1055\n",
      "Epoch 47/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 6.4329e-04 - acc: 1.0000 - val_loss: 11.5812 - val_acc: 0.1045\n",
      "Epoch 48/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.9763e-04 - acc: 1.0000 - val_loss: 11.6678 - val_acc: 0.1028\n",
      "Epoch 49/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.7798e-04 - acc: 1.0000 - val_loss: 11.7264 - val_acc: 0.1028\n",
      "Epoch 50/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.3161e-04 - acc: 1.0000 - val_loss: 11.7508 - val_acc: 0.1027\n",
      "Epoch 51/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.1178e-04 - acc: 1.0000 - val_loss: 11.7941 - val_acc: 0.1019\n",
      "Epoch 52/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 9.4962e-05 - acc: 1.0000 - val_loss: 11.8265 - val_acc: 0.1016\n",
      "Epoch 53/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 8.5254e-05 - acc: 1.0000 - val_loss: 11.8470 - val_acc: 0.1019\n",
      "Epoch 54/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 7.6479e-05 - acc: 1.0000 - val_loss: 11.8650 - val_acc: 0.1017\n",
      "Epoch 55/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 7.0586e-05 - acc: 1.0000 - val_loss: 11.8861 - val_acc: 0.1015\n",
      "Epoch 56/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 6.5323e-05 - acc: 1.0000 - val_loss: 11.9055 - val_acc: 0.1014\n",
      "Epoch 57/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 6.0625e-05 - acc: 1.0000 - val_loss: 11.9247 - val_acc: 0.1010\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 57us/step - loss: 5.7267e-05 - acc: 1.0000 - val_loss: 11.9276 - val_acc: 0.1015\n",
      "Epoch 59/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 5.3644e-05 - acc: 1.0000 - val_loss: 11.9544 - val_acc: 0.1012\n",
      "Epoch 60/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 5.0875e-05 - acc: 1.0000 - val_loss: 11.9563 - val_acc: 0.1011\n",
      "Epoch 61/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 4.8118e-05 - acc: 1.0000 - val_loss: 11.9709 - val_acc: 0.1014\n",
      "Epoch 62/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 4.5896e-05 - acc: 1.0000 - val_loss: 11.9801 - val_acc: 0.1013\n",
      "Epoch 63/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 4.3787e-05 - acc: 1.0000 - val_loss: 11.9933 - val_acc: 0.1014\n",
      "Epoch 64/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 4.1809e-05 - acc: 1.0000 - val_loss: 11.9995 - val_acc: 0.1013\n",
      "Epoch 65/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 4.0082e-05 - acc: 1.0000 - val_loss: 12.0112 - val_acc: 0.1013\n",
      "Epoch 66/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.8416e-05 - acc: 1.0000 - val_loss: 12.0239 - val_acc: 0.1016\n",
      "Epoch 67/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.7012e-05 - acc: 1.0000 - val_loss: 12.0327 - val_acc: 0.1009\n",
      "Epoch 68/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.5635e-05 - acc: 1.0000 - val_loss: 12.0433 - val_acc: 0.1005\n",
      "Epoch 69/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.4373e-05 - acc: 1.0000 - val_loss: 12.0518 - val_acc: 0.1013\n",
      "Epoch 70/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.3197e-05 - acc: 1.0000 - val_loss: 12.0541 - val_acc: 0.1011\n",
      "Epoch 71/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.2098e-05 - acc: 1.0000 - val_loss: 12.0622 - val_acc: 0.1013\n",
      "Epoch 72/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.1091e-05 - acc: 1.0000 - val_loss: 12.0658 - val_acc: 0.1013\n",
      "Epoch 73/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.0095e-05 - acc: 1.0000 - val_loss: 12.0787 - val_acc: 0.1008\n",
      "Epoch 74/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.9191e-05 - acc: 1.0000 - val_loss: 12.0839 - val_acc: 0.1011\n",
      "Epoch 75/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.8432e-05 - acc: 1.0000 - val_loss: 12.0935 - val_acc: 0.1008\n",
      "Epoch 76/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.7573e-05 - acc: 1.0000 - val_loss: 12.0962 - val_acc: 0.1010\n",
      "Epoch 77/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.6835e-05 - acc: 1.0000 - val_loss: 12.1060 - val_acc: 0.1010\n",
      "Epoch 78/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.6136e-05 - acc: 1.0000 - val_loss: 12.1127 - val_acc: 0.1011\n",
      "Epoch 79/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.5473e-05 - acc: 1.0000 - val_loss: 12.1165 - val_acc: 0.1013\n",
      "Epoch 80/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.4816e-05 - acc: 1.0000 - val_loss: 12.1235 - val_acc: 0.1015\n",
      "Epoch 81/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.4204e-05 - acc: 1.0000 - val_loss: 12.1270 - val_acc: 0.1016\n",
      "Epoch 82/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.3631e-05 - acc: 1.0000 - val_loss: 12.1320 - val_acc: 0.1014\n",
      "Epoch 83/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.3049e-05 - acc: 1.0000 - val_loss: 12.1409 - val_acc: 0.1012\n",
      "Epoch 84/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2556e-05 - acc: 1.0000 - val_loss: 12.1449 - val_acc: 0.1013\n",
      "Epoch 85/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.2025e-05 - acc: 1.0000 - val_loss: 12.1486 - val_acc: 0.1014\n",
      "Epoch 86/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.1529e-05 - acc: 1.0000 - val_loss: 12.1526 - val_acc: 0.1008\n",
      "Epoch 87/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.1099e-05 - acc: 1.0000 - val_loss: 12.1600 - val_acc: 0.1013\n",
      "Epoch 88/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.0654e-05 - acc: 1.0000 - val_loss: 12.1639 - val_acc: 0.1014\n",
      "Epoch 89/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.0199e-05 - acc: 1.0000 - val_loss: 12.1730 - val_acc: 0.1013\n",
      "Epoch 90/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.9807e-05 - acc: 1.0000 - val_loss: 12.1720 - val_acc: 0.1014\n",
      "Epoch 91/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.9437e-05 - acc: 1.0000 - val_loss: 12.1771 - val_acc: 0.1015\n",
      "Epoch 92/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.9047e-05 - acc: 1.0000 - val_loss: 12.1813 - val_acc: 0.1015\n",
      "Epoch 93/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.8677e-05 - acc: 1.0000 - val_loss: 12.1876 - val_acc: 0.1015\n",
      "Epoch 94/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.8321e-05 - acc: 1.0000 - val_loss: 12.1883 - val_acc: 0.1011\n",
      "Epoch 95/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.7993e-05 - acc: 1.0000 - val_loss: 12.1920 - val_acc: 0.1014\n",
      "Epoch 96/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.7683e-05 - acc: 1.0000 - val_loss: 12.1979 - val_acc: 0.1012\n",
      "Epoch 97/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.7356e-05 - acc: 1.0000 - val_loss: 12.2020 - val_acc: 0.1016\n",
      "Epoch 98/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.7058e-05 - acc: 1.0000 - val_loss: 12.2069 - val_acc: 0.1015\n",
      "Epoch 99/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.6759e-05 - acc: 1.0000 - val_loss: 12.2104 - val_acc: 0.1014\n",
      "Epoch 100/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.6498e-05 - acc: 1.0000 - val_loss: 12.2116 - val_acc: 0.1016\n",
      "Epoch 101/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.6219e-05 - acc: 1.0000 - val_loss: 12.2162 - val_acc: 0.1013\n",
      "Epoch 102/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.5947e-05 - acc: 1.0000 - val_loss: 12.2188 - val_acc: 0.1015\n",
      "Epoch 103/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.5691e-05 - acc: 1.0000 - val_loss: 12.2212 - val_acc: 0.1013\n",
      "Epoch 104/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.5447e-05 - acc: 1.0000 - val_loss: 12.2276 - val_acc: 0.1013\n",
      "Epoch 105/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.5212e-05 - acc: 1.0000 - val_loss: 12.2271 - val_acc: 0.1015\n",
      "Epoch 106/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.4975e-05 - acc: 1.0000 - val_loss: 12.2336 - val_acc: 0.1014\n",
      "Epoch 107/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.4752e-05 - acc: 1.0000 - val_loss: 12.2355 - val_acc: 0.1015\n",
      "Epoch 108/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.4526e-05 - acc: 1.0000 - val_loss: 12.2379 - val_acc: 0.1012\n",
      "Epoch 109/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.4306e-05 - acc: 1.0000 - val_loss: 12.2431 - val_acc: 0.1014\n",
      "Epoch 110/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.4109e-05 - acc: 1.0000 - val_loss: 12.2445 - val_acc: 0.1016\n",
      "Epoch 111/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.3906e-05 - acc: 1.0000 - val_loss: 12.2484 - val_acc: 0.1014\n",
      "Epoch 112/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.3711e-05 - acc: 1.0000 - val_loss: 12.2491 - val_acc: 0.1014\n",
      "Epoch 113/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.3518e-05 - acc: 1.0000 - val_loss: 12.2527 - val_acc: 0.1015\n",
      "Epoch 114/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.3339e-05 - acc: 1.0000 - val_loss: 12.2542 - val_acc: 0.1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.3156e-05 - acc: 1.0000 - val_loss: 12.2573 - val_acc: 0.1017\n",
      "Epoch 116/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.2983e-05 - acc: 1.0000 - val_loss: 12.2599 - val_acc: 0.1013\n",
      "Epoch 117/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.2809e-05 - acc: 1.0000 - val_loss: 12.2640 - val_acc: 0.1015\n",
      "Epoch 118/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.2639e-05 - acc: 1.0000 - val_loss: 12.2688 - val_acc: 0.1019\n",
      "Epoch 119/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.2474e-05 - acc: 1.0000 - val_loss: 12.2722 - val_acc: 0.1019\n",
      "Epoch 120/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.2323e-05 - acc: 1.0000 - val_loss: 12.2737 - val_acc: 0.1018\n",
      "Epoch 121/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.2167e-05 - acc: 1.0000 - val_loss: 12.2761 - val_acc: 0.1016\n",
      "Epoch 122/500\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.2016e-05 - acc: 1.0000 - val_loss: 12.2788 - val_acc: 0.1017\n",
      "Epoch 123/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.1868e-05 - acc: 1.0000 - val_loss: 12.2830 - val_acc: 0.1018\n",
      "Epoch 124/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 1.1722e-05 - acc: 1.0000 - val_loss: 12.2837 - val_acc: 0.1019\n",
      "Epoch 125/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.1587e-05 - acc: 1.0000 - val_loss: 12.2851 - val_acc: 0.1017\n",
      "Epoch 126/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.1447e-05 - acc: 1.0000 - val_loss: 12.2878 - val_acc: 0.1016\n",
      "Epoch 127/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 1.1315e-05 - acc: 1.0000 - val_loss: 12.2896 - val_acc: 0.1018\n",
      "Epoch 128/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.1182e-05 - acc: 1.0000 - val_loss: 12.2915 - val_acc: 0.1015\n",
      "Epoch 129/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 1.1057e-05 - acc: 1.0000 - val_loss: 12.2968 - val_acc: 0.1019\n",
      "Epoch 130/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.0935e-05 - acc: 1.0000 - val_loss: 12.2976 - val_acc: 0.1015\n",
      "Epoch 131/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.0802e-05 - acc: 1.0000 - val_loss: 12.3000 - val_acc: 0.1016\n",
      "Epoch 132/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 1.0685e-05 - acc: 1.0000 - val_loss: 12.3026 - val_acc: 0.1018\n",
      "Epoch 133/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 1.0568e-05 - acc: 1.0000 - val_loss: 12.3049 - val_acc: 0.1016\n",
      "Epoch 134/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.0455e-05 - acc: 1.0000 - val_loss: 12.3089 - val_acc: 0.1018\n",
      "Epoch 135/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.0337e-05 - acc: 1.0000 - val_loss: 12.3091 - val_acc: 0.1017\n",
      "Epoch 136/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.0237e-05 - acc: 1.0000 - val_loss: 12.3120 - val_acc: 0.1015\n",
      "Epoch 137/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 1.0125e-05 - acc: 1.0000 - val_loss: 12.3124 - val_acc: 0.1017\n",
      "Epoch 138/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 1.0021e-05 - acc: 1.0000 - val_loss: 12.3145 - val_acc: 0.1017\n",
      "Epoch 139/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 9.9133e-06 - acc: 1.0000 - val_loss: 12.3163 - val_acc: 0.1018\n",
      "Epoch 140/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 9.8163e-06 - acc: 1.0000 - val_loss: 12.3188 - val_acc: 0.1021\n",
      "Epoch 141/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 9.7135e-06 - acc: 1.0000 - val_loss: 12.3223 - val_acc: 0.1017\n",
      "Epoch 142/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 9.6187e-06 - acc: 1.0000 - val_loss: 12.3241 - val_acc: 0.1016\n",
      "Epoch 143/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 9.5249e-06 - acc: 1.0000 - val_loss: 12.3249 - val_acc: 0.1018\n",
      "Epoch 144/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 9.4334e-06 - acc: 1.0000 - val_loss: 12.3274 - val_acc: 0.1018\n",
      "Epoch 145/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 9.3409e-06 - acc: 1.0000 - val_loss: 12.3315 - val_acc: 0.1018\n",
      "Epoch 146/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 9.2510e-06 - acc: 1.0000 - val_loss: 12.3312 - val_acc: 0.1015\n",
      "Epoch 147/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 9.1611e-06 - acc: 1.0000 - val_loss: 12.3340 - val_acc: 0.1018\n",
      "Epoch 148/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 9.0711e-06 - acc: 1.0000 - val_loss: 12.3366 - val_acc: 0.1019\n",
      "Epoch 149/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.9884e-06 - acc: 1.0000 - val_loss: 12.3379 - val_acc: 0.1015\n",
      "Epoch 150/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.9037e-06 - acc: 1.0000 - val_loss: 12.3397 - val_acc: 0.1016\n",
      "Epoch 151/500\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 8.8266e-06 - acc: 1.0000 - val_loss: 12.3410 - val_acc: 0.1018\n",
      "Epoch 152/500\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 8.7431e-06 - acc: 1.0000 - val_loss: 12.3432 - val_acc: 0.1015\n",
      "Epoch 153/500\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 8.6620e-06 - acc: 1.0000 - val_loss: 12.3447 - val_acc: 0.1015\n",
      "Epoch 154/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.5817e-06 - acc: 1.0000 - val_loss: 12.3459 - val_acc: 0.1015\n",
      "Epoch 155/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.5133e-06 - acc: 1.0000 - val_loss: 12.3482 - val_acc: 0.1016\n",
      "Epoch 156/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.4336e-06 - acc: 1.0000 - val_loss: 12.3490 - val_acc: 0.1016\n",
      "Epoch 157/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.3614e-06 - acc: 1.0000 - val_loss: 12.3511 - val_acc: 0.1016\n",
      "Epoch 158/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.2884e-06 - acc: 1.0000 - val_loss: 12.3535 - val_acc: 0.1014\n",
      "Epoch 159/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.2163e-06 - acc: 1.0000 - val_loss: 12.3533 - val_acc: 0.1018\n",
      "Epoch 160/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.1449e-06 - acc: 1.0000 - val_loss: 12.3564 - val_acc: 0.1019\n",
      "Epoch 161/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.0800e-06 - acc: 1.0000 - val_loss: 12.3580 - val_acc: 0.1015\n",
      "Epoch 162/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.0091e-06 - acc: 1.0000 - val_loss: 12.3603 - val_acc: 0.1013\n",
      "Epoch 163/500\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 7.9401e-06 - acc: 1.0000 - val_loss: 12.3611 - val_acc: 0.1014\n",
      "Epoch 164/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 7.8785e-06 - acc: 1.0000 - val_loss: 12.3634 - val_acc: 0.1017\n",
      "Epoch 165/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 7.8120e-06 - acc: 1.0000 - val_loss: 12.3649 - val_acc: 0.1014\n",
      "Epoch 166/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 7.7485e-06 - acc: 1.0000 - val_loss: 12.3660 - val_acc: 0.1017\n",
      "Epoch 167/500\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 7.6852e-06 - acc: 1.0000 - val_loss: 12.3666 - val_acc: 0.1017\n",
      "Epoch 168/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.6276e-06 - acc: 1.0000 - val_loss: 12.3685 - val_acc: 0.1016\n",
      "Epoch 169/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.5666e-06 - acc: 1.0000 - val_loss: 12.3711 - val_acc: 0.1017\n",
      "Epoch 170/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.5044e-06 - acc: 1.0000 - val_loss: 12.3720 - val_acc: 0.1019\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.4466e-06 - acc: 1.0000 - val_loss: 12.3736 - val_acc: 0.1017\n",
      "Epoch 172/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.3873e-06 - acc: 1.0000 - val_loss: 12.3756 - val_acc: 0.1016\n",
      "Epoch 173/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 7.3320e-06 - acc: 1.0000 - val_loss: 12.3768 - val_acc: 0.1016\n",
      "Epoch 174/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.2770e-06 - acc: 1.0000 - val_loss: 12.3771 - val_acc: 0.1016\n",
      "Epoch 175/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.2199e-06 - acc: 1.0000 - val_loss: 12.3796 - val_acc: 0.1016\n",
      "Epoch 176/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.1679e-06 - acc: 1.0000 - val_loss: 12.3814 - val_acc: 0.1016\n",
      "Epoch 177/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.1129e-06 - acc: 1.0000 - val_loss: 12.3828 - val_acc: 0.1016\n",
      "Epoch 178/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.0596e-06 - acc: 1.0000 - val_loss: 12.3844 - val_acc: 0.1015\n",
      "Epoch 179/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 7.0064e-06 - acc: 1.0000 - val_loss: 12.3852 - val_acc: 0.1016\n",
      "Epoch 180/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 6.9545e-06 - acc: 1.0000 - val_loss: 12.3865 - val_acc: 0.1016\n",
      "Epoch 181/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.9057e-06 - acc: 1.0000 - val_loss: 12.3886 - val_acc: 0.1017\n",
      "Epoch 182/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 6.8573e-06 - acc: 1.0000 - val_loss: 12.3887 - val_acc: 0.1015\n",
      "Epoch 183/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.8051e-06 - acc: 1.0000 - val_loss: 12.3900 - val_acc: 0.1018\n",
      "Epoch 184/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.7564e-06 - acc: 1.0000 - val_loss: 12.3927 - val_acc: 0.1017\n",
      "Epoch 185/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.7104e-06 - acc: 1.0000 - val_loss: 12.3925 - val_acc: 0.1016\n",
      "Epoch 186/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.6633e-06 - acc: 1.0000 - val_loss: 12.3945 - val_acc: 0.1015\n",
      "Epoch 187/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.6154e-06 - acc: 1.0000 - val_loss: 12.3973 - val_acc: 0.1018\n",
      "Epoch 188/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.5697e-06 - acc: 1.0000 - val_loss: 12.3976 - val_acc: 0.1017\n",
      "Epoch 189/500\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 6.5259e-06 - acc: 1.0000 - val_loss: 12.3986 - val_acc: 0.1017\n",
      "Epoch 190/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.4801e-06 - acc: 1.0000 - val_loss: 12.3999 - val_acc: 0.1017\n",
      "Epoch 191/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.4376e-06 - acc: 1.0000 - val_loss: 12.4016 - val_acc: 0.1017\n",
      "Epoch 192/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.3916e-06 - acc: 1.0000 - val_loss: 12.4032 - val_acc: 0.1018\n",
      "Epoch 193/500\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 6.3505e-06 - acc: 1.0000 - val_loss: 12.4046 - val_acc: 0.1017\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Fast Gradient Sign Method (FGSM) attack object and graph\n",
    "\n",
    "gen_adv = GenAdv(sess)\n",
    "\n",
    "losses = np.zeros((gen_steps, len(attack_names), num_points))\n",
    "accuracies = np.zeros((gen_steps, len(attack_names), num_points))\n",
    "\n",
    "directory = 'model_r{}'.format(run_ident)\n",
    "if not from_saved_model and not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "for gen in range(10, gen_steps):\n",
    "    print('Gen: {}'.format(gen))\n",
    "    \n",
    "    #callbacks = [TensorBoard(log_dir='./logs/overfitting_r{}_g{}'.format(run_ident, gen)),\n",
    "    #           EarlyStopping(monitor='loss', min_delta=1e-5, patience=5, verbose=0, mode='auto')] # 0 - 6\n",
    "    #callbacks = [TensorBoard(log_dir='./logs/overfitting_r{}_g{}'.format(run_ident, gen)),\n",
    "    #           EarlyStopping(monitor='loss', min_delta=1e-5, patience=30, verbose=0, mode='auto')] # 6 - 9\n",
    "    callbacks = [TensorBoard(log_dir='./logs/overfitting_r{}_g{}'.format(run_ident, gen)),\n",
    "                EarlyStopping(monitor='loss', min_delta=1e-5, patience=60, verbose=0, mode='auto')] # 10\n",
    "    \n",
    "    # Shuffle Labels\n",
    "    prob_sel = gen / (gen_steps-1)\n",
    "    print('Proability of Randomization: {}'.format(prob_sel))\n",
    "    \n",
    "    # Extract Sample to Edit\n",
    "    Y_rand = np.copy(Y_train)\n",
    "    sel = np.random.choice([False, True], size=(Y_rand.shape[0],), p=(1-prob_sel, prob_sel))\n",
    "    Y_sel = Y_rand[sel,:]\n",
    "    \n",
    "    np.random.shuffle(Y_sel)\n",
    "    \n",
    "    # Debug\n",
    "    rand_equal = np.equal(Y_rand[sel,:], Y_sel)\n",
    "    rand_mean = np.mean(np.all(rand_equal, axis=1))\n",
    "    print('Rand mean (only shuffled): {}'.format(rand_mean))\n",
    "    # Debug\n",
    "    \n",
    "    Y_rand[sel,:] = np.copy(Y_sel)\n",
    "    \n",
    "    # Debug\n",
    "    rand_equal = np.equal(Y_rand[sel,:], Y_sel)\n",
    "    rand_mean = np.mean(np.all(rand_equal, axis=1))\n",
    "    print('Rand mean (Should be 1): {}'.format(rand_mean))\n",
    "    # Debug\n",
    "    \n",
    "    # Debug\n",
    "    rand_equal = np.equal(Y_rand, Y_train)\n",
    "    rand_mean = np.mean(np.all(rand_equal, axis=1))\n",
    "    print('Rand mean (all): {}'.format(rand_mean))\n",
    "    # Debug\n",
    "    \n",
    "    if from_saved_model:\n",
    "        model = load_model('model_r{}/model_g{}.h5'.format(run_ident, gen))\n",
    "    else:\n",
    "        reset_weights(model)\n",
    "        model.fit(X_train, Y_rand,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_test, Y_test),\n",
    "                  callbacks=callbacks)\n",
    "        model.save('model_r{}/model_g{}.h5'.format(run_ident, gen))\n",
    "\n",
    "    if run_attack:\n",
    "        loss, accuracy = gen_adv.evaluate_model(model, X_test[attack_start:attack_end, :], \n",
    "                                                Y_test[attack_start:attack_end], \n",
    "                                                attack_names, num_points=num_points)\n",
    "        losses[gen,:,:] = loss\n",
    "        accuracies[gen,:,:] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_attack:\n",
    "    np.save('loss_r{}.npy'.format(run_ident), losses)\n",
    "    np.save('accuracy_r{}.npy'.format(run_ident), accuracies)\n",
    "    max_loss = losses.flatten().max()\n",
    "    max_accuracy = accuracies.flatten().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func(gen):\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    plt.subplot(121)\n",
    "    for index, attack_name in enumerate(attack_names):\n",
    "        x_plt = np.linspace(0, 0.5, num_points)\n",
    "        y_plt = losses[epoch, index, :].flatten()\n",
    "        plt.plot(x_plt, y_plt, label=attack_name)\n",
    "    plt.title('Adversarial Loss')\n",
    "    plt.xlabel('Attack Strength')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(ymax=max_loss)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    for index, attack_name in enumerate(attack_names):\n",
    "        x_plt = np.linspace(0, 0.5, num_points)\n",
    "        y_plt = accuracies[epoch, index, :].flatten()\n",
    "        plt.plot(x_plt, y_plt, label=attack_name)\n",
    "    plt.title('Adversarial Accuracy')\n",
    "    plt.xlabel('Attack Strength')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(ymax=max_accuracy)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_attack:\n",
    "    interact(plot_func, gen=widgets.IntSlider(min=0,max=gen_steps-1,step=1,value=0));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
